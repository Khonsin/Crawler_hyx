2022-03-07 16:28:25 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: Crawl_hyx)
2022-03-07 16:28:25 [scrapy.utils.log] INFO: Versions: lxml 4.7.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.1.0, Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021), cryptography 36.0.1, Platform Windows-10-10.0.19044-SP0
2022-03-07 16:28:25 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2022-03-07 16:28:25 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'Crawl_hyx',
 'LOG_FILE': 'log/scrapy_2022_3_7_0.log',
 'NEWSPIDER_MODULE': 'Crawl_hyx.spiders',
 'SPIDER_MODULES': ['Crawl_hyx.spiders']}
2022-03-07 16:28:26 [scrapy.extensions.telnet] INFO: Telnet Password: 7fbfa2860a77a613
2022-03-07 16:28:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2022-03-07 16:28:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session {"capabilities": {"firstMatch": [{}], "alwaysMatch": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": ["--headless", "--disable-gpu", "--no-sandbox", "--headless"]}}}, "desiredCapabilities": {"browserName": "chrome", "pageLoadStrategy": "normal", "goog:chromeOptions": {"extensions": [], "args": ["--headless", "--disable-gpu", "--no-sandbox", "--headless"]}}}
2022-03-07 16:28:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): localhost:56522
2022-03-07 16:28:28 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session HTTP/1.1" 200 797
2022-03-07 16:28:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:28:28 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/timeouts {"implicit": 1000}
2022-03-07 16:28:28 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/timeouts HTTP/1.1" 200 14
2022-03-07 16:28:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:28:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'Crawl_hyx.middlewares.CrawlHyxDownloaderMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2022-03-07 16:28:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-03-07 16:28:28 [scrapy.middleware] INFO: Enabled item pipelines:
['Crawl_hyx.pipelines.WanyiPipeline',
 'Crawl_hyx.pipelines.TengxunPipeline',
 'Crawl_hyx.pipelines.BaidubaikePipeline',
 'Crawl_hyx.pipelines.BaiduPipeline']
2022-03-07 16:28:28 [scrapy.core.engine] INFO: Spider opened
2022-03-07 16:28:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 16:28:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-03-07 16:28:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://war.163.com/> from <GET http://war.163.com/>
2022-03-07 16:28:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://war.163.com/"}
2022-03-07 16:32:02 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 16:32:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:32:04 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 16:32:04 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 380637
2022-03-07 16:32:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:32:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://war.163.com/> (referer: None)
2022-03-07 16:32:04 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 16:32:04 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://war.163.com/"}
2022-03-07 16:32:37 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 16:32:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:32:37 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/execute/sync {"script": "return document.body.scrollHeight;", "args": []}
2022-03-07 16:32:37 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/execute/sync HTTP/1.1" 200 15
2022-03-07 16:32:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:32:39 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/execute/sync {"script": "window.scrollBy(0,1000)", "args": []}
2022-03-07 16:32:39 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/execute/sync HTTP/1.1" 200 14
2022-03-07 16:32:39 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:32:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/execute/sync {"script": "window.scrollBy(0,1000)", "args": []}
2022-03-07 16:32:41 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/execute/sync HTTP/1.1" 200 14
2022-03-07 16:32:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:32:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/execute/sync {"script": "window.scrollBy(0,1000)", "args": []}
2022-03-07 16:32:43 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/execute/sync HTTP/1.1" 200 14
2022-03-07 16:32:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:32:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/execute/sync {"script": "window.scrollBy(0,1000)", "args": []}
2022-03-07 16:32:45 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/execute/sync HTTP/1.1" 200 14
2022-03-07 16:32:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:32:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/execute/sync {"script": "window.scrollBy(0,1000)", "args": []}
2022-03-07 16:32:47 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/execute/sync HTTP/1.1" 200 14
2022-03-07 16:32:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:32:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/execute/sync {"script": "window.scrollBy(0,1000)", "args": []}
2022-03-07 16:32:49 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/execute/sync HTTP/1.1" 200 14
2022-03-07 16:32:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:32:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/execute/sync {"script": "return document.body.scrollHeight;", "args": []}
2022-03-07 16:32:49 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/execute/sync HTTP/1.1" 200 15
2022-03-07 16:32:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:32:49 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 16:32:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1R6IE4G0514R9OJ.html"}
2022-03-07 16:35:27 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 16:35:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:35:29 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 16:35:30 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 206912
2022-03-07 16:35:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:35:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1R6IE4G0514R9OJ.html> (referer: https://war.163.com/)
2022-03-07 16:35:30 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 16:35:30 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1S5BEVU0514R9OJ.html"}
2022-03-07 16:36:16 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 16:36:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:36:18 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 16:36:18 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 196978
2022-03-07 16:36:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:36:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1S5BEVU0514R9OJ.html> (referer: https://war.163.com/)
2022-03-07 16:36:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1RABH1E0514R9OJ.html"}
2022-03-07 16:37:53 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 16:37:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:37:55 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 16:37:55 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 217174
2022-03-07 16:37:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:37:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1RABH1E0514R9OJ.html> (referer: https://war.163.com/)
2022-03-07 16:37:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1S5Q1VH05504DOH.html"}
2022-03-07 16:40:58 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 16:40:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:41:00 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 16:41:00 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 211595
2022-03-07 16:41:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:41:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1S5Q1VH05504DOH.html> (referer: https://war.163.com/)
2022-03-07 16:41:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1RDE6H50514R9OJ.html"}
2022-03-07 16:41:21 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 500 1171
2022-03-07 16:41:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:41:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RTQ4DF0514R9OJ.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1RTQ4DF0514R9OJ.html took longer than 180.0 seconds..
2022-03-07 16:41:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/war/article/H1RNH9OH000181KT.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/war/article/H1RNH9OH000181KT.html took longer than 180.0 seconds..
2022-03-07 16:41:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1S7KJFM0514R9OJ.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1S7KJFM0514R9OJ.html took longer than 180.0 seconds..
2022-03-07 16:41:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1S7KJPF0514R9OJ.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1S7KJPF0514R9OJ.html took longer than 180.0 seconds..
2022-03-07 16:41:21 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 16:41:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1SA5GSN0514R9P4.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1SA5GSN0514R9P4.html took longer than 180.0 seconds..
2022-03-07 16:41:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1QKIBFK0514R9OJ.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1QKIBFK0514R9OJ.html took longer than 180.0 seconds..
2022-03-07 16:41:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1QSNHQR0514R9OJ.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1QSNHQR0514R9OJ.html took longer than 180.0 seconds..
2022-03-07 16:41:21 [scrapy.core.scraper] ERROR: Error processing {'author': '环球网资讯',
 'content': '\n'
            '                    '
            '目前，在乌克兰的中国同胞绝大部分已撤离。当前，乌紧张形势还在不断恶化，且有急剧升温之势，中国驻乌克兰使馆在此谨提醒尚在乌的中国同胞尽快自乌离境。\n'
            '                ',
 'followNum': '1503247',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 05:29:19\u3000来源: ',
 'readNum': '36',
 'regTime': '',
 'retweetNum': '5',
 'source': '网易军事',
 'timestamp': '20220307164121',
 'title': '中国驻乌克兰大使馆提醒尚在乌的中国同胞尽快自乌离境',
 'url': 'https://www.163.com/dy/article/H1R6IE4G0514R9OJ.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 16:41:22 [scrapy.core.scraper] ERROR: Error processing {'author': '环球网资讯',
 'content': '\n'
            '                    '
            '俄罗斯国防部发布的一段视频显示，俄空天军苏-35战机参与执行特别军事行动相关任务。#俄乌局势#（总台记者王斌）\n'
            '                ',
 'followNum': '1503247',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 14:27:16\u3000来源: ',
 'readNum': None,
 'regTime': '',
 'retweetNum': None,
 'source': '网易军事',
 'timestamp': '20220307164122',
 'title': '俄公布苏35执行特别军事任务视频',
 'url': 'https://www.163.com/dy/article/H1S5BEVU0514R9OJ.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 16:41:22 [scrapy.core.scraper] ERROR: Error processing {'author': '环球网资讯',
 'content': '\n'
            '                    编辑同志：俄乌冲突多日来牵动各方神经。土耳其日前宣布 '
            '“关闭”黑海海峡，狠狠刷了一波存在感。土耳其的权利从何而来？涉及此事的《蒙特勒公约》又是怎么一回事？安徽读者 '
            '孙海蓉事实上，上面所说的“关闭”并不是真正的封锁海峡，而是不让各国军舰通过。至于土耳其的权利从何而来，这就不得不提及关于黑海海峡问题最权威且仍为各国遵循的《蒙特勒公约》。黑海海峡又称土耳其海峡，作为连接黑海和地中海的咽喉之地，其战略地位十分重要。欧洲大国历史上曾围绕此地展开数百年争夺。第一次世界大战后，土耳其作为战败国一度丧失对黑海海峡的主权，整个海峡地区实行非军事化，不得设防和派驻武装力量。随着法西斯政权的建立及其战争步伐的迈进，欧洲局势日益紧张。有关国家出于维护自身利益考虑，于1936年6月在瑞士蒙特勒召开会议制定新的海峡制度，《蒙特勒公约》由此诞生。土耳其作为该公约的主要执行方，完全恢复了对黑海海峡的主权。由于特定的历史背景，公约有着浓厚的军事色彩。公约确立的海峡通行自由原则包括：平时和战时各国商船均可自由通过；平时黑海沿岸国家的军舰可自由通过海峡，非沿岸国家军舰通过受限，即同一时期通过的军舰总吨位不得超过1.5万吨，在黑海停留的船只总吨位不得超过3万吨，在特定情况下不得超过4.5万吨，停留时间不得超过21 '
            '天；任何一个非沿岸国家舰队通过海峡的船只不得超过9 '
            '艘，总吨位不得超过1.5万吨；在战时若土耳其为中立国，各交战国军舰不得通过海峡；若土耳其为参战国，则由土耳其决定是否允许别国军舰通过。公约对于维护黑海地区秩序起到重要作用，在历史上也基本得到各方遵守。但随着近年来俄罗斯和欧美国家关系恶化，美欧等非沿岸国试图修改公约规定，为军事力量进入黑海打开方便之门。俄罗斯出于维护国家安全考虑成为公约的维护者。土耳其则利用这一特殊权利不断彰显其地缘政治地位。2014年克里米亚事件以来，土方多次违反公约精神，放行北约舰队进入黑海，且停留时间不断增加，有的长达120天之久。（西山）\n'
            '                ',
 'followNum': '1503247',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 06:35:27\u3000来源: ',
 'readNum': '213',
 'regTime': '',
 'retweetNum': '10',
 'source': '网易军事',
 'timestamp': '20220307164122',
 'title': '【答读者问】土耳其为何有权“关闭”黑海海峡？',
 'url': 'https://www.163.com/dy/article/H1RABH1E0514R9OJ.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 16:41:22 [scrapy.core.scraper] ERROR: Error processing {'author': '环球时报军事',
 'content': '\n'
            '                    '
            '据《印度快报》3月7日报道，6日，在印度旁遮普邦阿姆利则靠近巴基斯坦边境的一个边防营总部，5名边境安全部队（BSF）士兵被打死。据称其中一人用自己的军用枪支向同事开枪，最后他自己也中弹身亡。印度边境安全部队将这起事件描述为自相残杀案件，并命令法院进行调查，同时当地警方已经立案。边境安全部队的一名官员阿西夫·贾拉尔（Asif '
            'Jalal）说：“事件正在调查中，我们已经报警，警方也将进行调查。”据这家印媒报道，印度边境安全部队消息人士称，B连队的士兵萨特帕·S·K在上午9时45分左右开枪，打死了托拉斯卡尔·D·S、拉姆·比诺德、拉坦·辛格和巴尔金德·库马尔。报道截图消息人士还说，萨特帕还向144营的指挥官萨蒂什·米什拉的车辆开火，米什拉安然无恙地逃脱了。尽管有消息称，萨特帕“对自己的工作时间感到不满”，但贾拉尔否认这起事件与工作或之前的敌意有关。上午11时左右，几名受害者在医院被宣布“死亡”。另一名士官尼哈尔·辛格在事件中受重伤，目前正在接受治疗。印度边境安全部队在一份声明中称：“这是发生在144营的一起自相残杀事件，在6名受伤的士兵中，5名已经失去了生命，其中一名伤者伤势严重。法庭已下令调查。”当地警方证实，所有受害者都死于枪伤，但“不确定”萨特帕本人是如何被杀的。阿姆利则的一名警官说：“边境安全部队官员坚称没有发生交火，萨特帕是在去医院的路上死亡的。”据这家印媒援引警方消息人士的话称，萨特帕拿起武器，来到托拉斯卡尔工作的办公室，向他开枪。消息人士称，随后枪手闯入营房，开始无差别地开枪，打死了另外三人。甚至在指挥官到达营房时，萨特帕还在向指挥官的汽车开火，随后离开现场，进入附近的一家边防部队医院。消息人士说，“他还在那里向空中开枪。”警方消息人士援引边防部队官员的话猜测，一颗子弹可能从医院地板上反弹，击中了萨特帕自己。印媒提到，由于其部队在高压力边境地区服役，印度边防部队以前也曾发生过类似事件。（编辑：DXY）\n'
            '                ',
 'followNum': '231962',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 14:35:15\u3000来源: ',
 'readNum': '274',
 'regTime': '',
 'retweetNum': '6',
 'source': '网易军事',
 'timestamp': '20220307164122',
 'title': '印度边境发生惨案！一名边防士兵拿枪对准自己人，4名同事死亡',
 'url': 'https://www.163.com/dy/article/H1S5Q1VH05504DOH.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 16:41:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.163.com/dy/article/H1RDE6H50514R9OJ.html>
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
StopIteration: <200 https://www.163.com/dy/article/H1RDE6H50514R9OJ.html>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_response
    response = yield deferred_from_coro(method(request=request, response=response, spider=spider))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\middlewares.py", line 70, in process_response
    bro.get(request.url)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 436, in get
    self.execute(Command.GET, {'url': url})
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 424, in execute
    self.error_handler.check_response(response)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 247, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: net::ERR_NAME_NOT_RESOLVED
  (Session info: headless chrome=99.0.4844.51)
Stacktrace:
Backtrace:
	Ordinal0 [0x007369A3+2582947]
	Ordinal0 [0x006CA6D1+2139857]
	Ordinal0 [0x005C3A98+1063576]
	Ordinal0 [0x005C0551+1049937]
	Ordinal0 [0x005B5D9D+1007005]
	Ordinal0 [0x005B6A0E+1010190]
	Ordinal0 [0x005B5FFE+1007614]
	Ordinal0 [0x005B55F0+1005040]
	Ordinal0 [0x005B4727+1001255]
	Ordinal0 [0x005B49E6+1001958]
	Ordinal0 [0x005C518A+1069450]
	Ordinal0 [0x006188FD+1411325]
	Ordinal0 [0x0060854C+1344844]
	Ordinal0 [0x0061834A+1409866]
	Ordinal0 [0x00608366+1344358]
	Ordinal0 [0x005E5176+1200502]
	Ordinal0 [0x005E6066+1204326]
	GetHandleVerifier [0x008DBE02+1675858]
	GetHandleVerifier [0x0099036C+2414524]
	GetHandleVerifier [0x007CBB01+560977]
	GetHandleVerifier [0x007CA8D3+556323]
	Ordinal0 [0x006D020E+2163214]
	Ordinal0 [0x006D5078+2183288]
	Ordinal0 [0x006D51C0+2183616]
	Ordinal0 [0x006DEE1C+2223644]
	BaseThreadInitThunk [0x76DBFA29+25]
	RtlGetAppContainerNamedObjectPath [0x77797A9E+286]
	RtlGetAppContainerNamedObjectPath [0x77797A6E+238]

2022-03-07 16:41:28 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 16:41:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1MIAREA0514R9OJ.html> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 16:41:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RKN0BU0514R9OJ.html> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 16:41:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RDE6CJ0514R9OJ.html> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 16:41:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RKQ69O05504DOH.html> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 16:41:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1MHGFPM05346936.html> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 16:41:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1MT39II05504DOH.html> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 16:41:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1MNR8F80514R9NP.html> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 16:41:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1R5U5SI0514R9OJ.html> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 16:42:28 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 16:42:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1N9J3MA0514BQ68.html"}
2022-03-07 16:47:56 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 500 1117
2022-03-07 16:47:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:47:56 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 16:47:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1MOA83705346936.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1MOA83705346936.html took longer than 180.0 seconds..
2022-03-07 16:47:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1N1KHO10514BQ68.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1N1KHO10514BQ68.html took longer than 180.0 seconds..
2022-03-07 16:47:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1NSL0ID053469LG.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1NSL0ID053469LG.html took longer than 180.0 seconds..
2022-03-07 16:47:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/news/article/H1OT9M0N0001899O.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/news/article/H1OT9M0N0001899O.html took longer than 180.0 seconds..
2022-03-07 16:47:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1KM6M9U0515CCSC.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1KM6M9U0515CCSC.html took longer than 180.0 seconds..
2022-03-07 16:47:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1P1TVU10514D3UH.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1P1TVU10514D3UH.html took longer than 180.0 seconds..
2022-03-07 16:47:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1P2DO610550LMMF.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1P2DO610550LMMF.html took longer than 180.0 seconds..
2022-03-07 16:47:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1QHMMD005504DOH.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1QHMMD005504DOH.html took longer than 180.0 seconds..
2022-03-07 16:47:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.163.com/dy/article/H1N9J3MA0514BQ68.html>
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
StopIteration: <200 https://www.163.com/dy/article/H1N9J3MA0514BQ68.html>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_response
    response = yield deferred_from_coro(method(request=request, response=response, spider=spider))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\middlewares.py", line 70, in process_response
    bro.get(request.url)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 436, in get
    self.execute(Command.GET, {'url': url})
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 424, in execute
    self.error_handler.check_response(response)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 247, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: timeout: Timed out receiving message from renderer: 288.319
  (Session info: headless chrome=99.0.4844.51)
Stacktrace:
Backtrace:
	Ordinal0 [0x007369A3+2582947]
	Ordinal0 [0x006CA6D1+2139857]
	Ordinal0 [0x005C3A98+1063576]
	Ordinal0 [0x005B5727+1005351]
	Ordinal0 [0x005B4727+1001255]
	Ordinal0 [0x005B4AF7+1002231]
	Ordinal0 [0x005BEF9F+1044383]
	Ordinal0 [0x005C962B+1087019]
	Ordinal0 [0x005CBD40+1097024]
	Ordinal0 [0x005B4DF6+1002998]
	Ordinal0 [0x005C94D5+1086677]
	Ordinal0 [0x00618616+1410582]
	Ordinal0 [0x00608366+1344358]
	Ordinal0 [0x005E5176+1200502]
	Ordinal0 [0x005E6066+1204326]
	GetHandleVerifier [0x008DBE02+1675858]
	GetHandleVerifier [0x0099036C+2414524]
	GetHandleVerifier [0x007CBB01+560977]
	GetHandleVerifier [0x007CA8D3+556323]
	Ordinal0 [0x006D020E+2163214]
	Ordinal0 [0x006D5078+2183288]
	Ordinal0 [0x006D51C0+2183616]
	Ordinal0 [0x006DEE1C+2223644]
	BaseThreadInitThunk [0x76DBFA29+25]
	RtlGetAppContainerNamedObjectPath [0x77797A9E+286]
	RtlGetAppContainerNamedObjectPath [0x77797A6E+238]

2022-03-07 16:48:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1O1V00105129QAF.html"}
2022-03-07 16:51:14 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 16:51:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:51:16 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 16:51:16 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 198260
2022-03-07 16:51:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:51:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1O1V00105129QAF.html> (referer: https://war.163.com/)
2022-03-07 16:51:16 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 16:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1NK0J9E0515CLPL.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1NK0J9E0515CLPL.html took longer than 180.0 seconds..
2022-03-07 16:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1O3K3DH05504DOH.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1O3K3DH05504DOH.html took longer than 180.0 seconds..
2022-03-07 16:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1O4QBUB0514R9OJ.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1O4QBUB0514R9OJ.html took longer than 180.0 seconds..
2022-03-07 16:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1NHO1EL0514FGV8.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1NHO1EL0514FGV8.html took longer than 180.0 seconds..
2022-03-07 16:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/war/article/H1P7AS7E000181KT.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/war/article/H1P7AS7E000181KT.html took longer than 180.0 seconds..
2022-03-07 16:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/war/article/H1P7E93V000181KT.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/war/article/H1P7E93V000181KT.html took longer than 180.0 seconds..
2022-03-07 16:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/war/article/H1P7KBE4000181KT.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/war/article/H1P7KBE4000181KT.html took longer than 180.0 seconds..
2022-03-07 16:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1P3379E0514EGPO.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1P3379E0514EGPO.html took longer than 180.0 seconds..
2022-03-07 16:51:16 [scrapy.core.scraper] ERROR: Error processing {'author': '南方都市报',
 'content': '\n'
            '                    '
            '阿富汗警察新兵结业典礼3月5日举行，阿富汗塔利班最神秘的领导人物之一、“哈卡尼网络”首领西拉贾丁·哈卡尼(SiraJuddin '
            'Haqqani)首次公开露脸。美国所谓的“悬赏”名单上唯一一张他的真人图片也只是模糊的半遮盖侧面照。西拉贾丁·哈卡尼（中）现身阿富汗警察新兵结业典礼据法新社报道，西拉贾丁·哈卡尼目前任塔利班临时政府代理内政部长，当日在结业典礼的阅兵式上，他的穿着打扮与许多塔利班高级官员一样：留着浓密的胡须，戴着黑色头巾和披着白色披肩。值得注意的是，包括巴基斯坦大使在内的几位外交官出现在阅兵式上。西拉贾丁·哈卡尼发表讲话时称，自己露面是为了“让人们知道我们的领导层有多大的价值”。“为了让你们满意，并建立信任……我出现在媒体上，与你们公开会面。”西拉贾丁·哈卡尼的穿着打扮与许多塔利班高级官员一样塔利班2021年8月15日控制阿富汗首都喀布尔，次日宣布阿富汗境内战事结束。2021年8月30日晚，最后一批驻阿美军撤离，美国结束在阿富汗长达近20年的战事。塔利班去年9月7日公布临时政府成员名单。领导班子以塔利班元老级人物为主，其中多人在1996年至2001年期间出任过重要职务。最高领导人海巴图拉·阿洪扎达（Hibatullah '
            'Akhundzada）则以埃米尔身份领导国家。据信40多岁的西拉贾丁·哈卡尼是阿洪扎达三名副手中级别最高的人物，被任命为代理内政部长。此前他几乎未曾在公开场合露面，临时政府成立至今，人们也只是从后面清楚地拍到他的背影。西拉贾丁·哈卡尼在阅兵式上塔利班官员在社交媒体上广泛分享了西拉贾丁·哈卡尼现身的照片，之前只发布过没有显示其面孔的图片，或者打马赛克的照片。法新社解读，西拉贾丁·哈卡尼的露面也表明，塔利班对自身的表现变得更加自信。美国情报部门将“哈卡尼网络”视为过去20年来针对阿富汗政府军及其西方盟友的一些最严重暴力事件的“罪魁祸首”，悬赏高达1000万美元来获得寻找西拉贾丁·哈卡尼的信息。悬赏名单展示的是一张其半遮盖侧面照，还有两张电脑合成照。美国“悬赏”西拉贾丁·哈卡尼的名单西拉贾丁·哈卡尼的父亲贾拉鲁丁·哈卡尼(Jalaluddin '
            'Haqqani)20世纪70年代创建了“哈卡尼网络”，80年代对抗入侵的苏联军队，获得美国中央情报局(CIA)的支持。“哈卡尼网络”后来与塔利班结盟，转而对抗美军。贾拉鲁丁·哈卡尼去世后，2018年西拉贾丁·哈卡尼接任“哈卡尼网络”首领。据报道，在阿富汗、巴基斯坦以及两国之间“哈卡尼网络”的心脏地带，他曾多次成为美国无人机袭击的目标。采写：南都记者 '
            '史明磊延伸阅读美国人走了还想插手？塔利班当面教训美国，还划出三道红线\n'
            '                ',
 'followNum': '3247757',
 'fromWhere': '',
 'pubTime': '\n                2022-03-06 00:11:04\u3000来源: ',
 'readNum': None,
 'regTime': '',
 'retweetNum': None,
 'source': '网易军事',
 'timestamp': '20220307165116',
 'title': ' 塔利班最神秘人物露真容！遭美国“悬赏”名单上仅有侧脸照',
 'url': 'https://www.163.com/dy/article/H1O1V00105129QAF.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 16:51:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://war.163.com/photoview/4T8E0001/2313491.html"}
2022-03-07 16:56:27 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 500 1117
2022-03-07 16:56:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:56:27 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 16:56:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RM9CE705504DOH.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1RM9CE705504DOH.html took longer than 180.0 seconds..
2022-03-07 16:56:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RKREE305504DOH.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1RKREE305504DOH.html took longer than 180.0 seconds..
2022-03-07 16:56:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RQF5JH05504DOH.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1RQF5JH05504DOH.html took longer than 180.0 seconds..
2022-03-07 16:56:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RT08260514R9P4.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1RT08260514R9P4.html took longer than 180.0 seconds..
2022-03-07 16:56:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RV2G0L0514R9OJ.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1RV2G0L0514R9OJ.html took longer than 180.0 seconds..
2022-03-07 16:56:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1S3I27A05504DOH.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1S3I27A05504DOH.html took longer than 180.0 seconds..
2022-03-07 16:56:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1S4HTIM0514R9OJ.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1S4HTIM0514R9OJ.html took longer than 180.0 seconds..
2022-03-07 16:56:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1S23EJ20514R9OJ.html> (failed 1 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1S23EJ20514R9OJ.html took longer than 180.0 seconds..
2022-03-07 16:56:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://war.163.com/photoview/4T8E0001/2313489.html> (failed 1 times): User timeout caused connection failure: Getting https://war.163.com/photoview/4T8E0001/2313489.html took longer than 180.0 seconds..
2022-03-07 16:56:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://war.163.com/photoview/4T8E0001/2313490.html> (failed 1 times): User timeout caused connection failure: Getting https://war.163.com/photoview/4T8E0001/2313490.html took longer than 180.0 seconds..
2022-03-07 16:56:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://war.163.com/photoview/4T8E0001/2313491.html>
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
StopIteration: <200 https://war.163.com/photoview/4T8E0001/2313491.html>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_response
    response = yield deferred_from_coro(method(request=request, response=response, spider=spider))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\middlewares.py", line 70, in process_response
    bro.get(request.url)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 436, in get
    self.execute(Command.GET, {'url': url})
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 424, in execute
    self.error_handler.check_response(response)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 247, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: timeout: Timed out receiving message from renderer: 287.186
  (Session info: headless chrome=99.0.4844.51)
Stacktrace:
Backtrace:
	Ordinal0 [0x007369A3+2582947]
	Ordinal0 [0x006CA6D1+2139857]
	Ordinal0 [0x005C3A98+1063576]
	Ordinal0 [0x005B5727+1005351]
	Ordinal0 [0x005B4727+1001255]
	Ordinal0 [0x005B4AF7+1002231]
	Ordinal0 [0x005BEF9F+1044383]
	Ordinal0 [0x005C962B+1087019]
	Ordinal0 [0x005CBD40+1097024]
	Ordinal0 [0x005B4DF6+1002998]
	Ordinal0 [0x005C94D5+1086677]
	Ordinal0 [0x00618616+1410582]
	Ordinal0 [0x00608366+1344358]
	Ordinal0 [0x005E5176+1200502]
	Ordinal0 [0x005E6066+1204326]
	GetHandleVerifier [0x008DBE02+1675858]
	GetHandleVerifier [0x0099036C+2414524]
	GetHandleVerifier [0x007CBB01+560977]
	GetHandleVerifier [0x007CA8D3+556323]
	Ordinal0 [0x006D020E+2163214]
	Ordinal0 [0x006D5078+2183288]
	Ordinal0 [0x006D51C0+2183616]
	Ordinal0 [0x006DEE1C+2223644]
	BaseThreadInitThunk [0x76DBFA29+25]
	RtlGetAppContainerNamedObjectPath [0x77797A9E+286]
	RtlGetAppContainerNamedObjectPath [0x77797A6E+238]

2022-03-07 16:56:28 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 16:56:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1S4HTIM0514R9OJ.html"}
2022-03-07 16:57:13 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 16:57:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:57:15 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 16:57:15 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 210361
2022-03-07 16:57:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:57:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1S4HTIM0514R9OJ.html> (referer: https://war.163.com/)
2022-03-07 16:57:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1S23EJ20514R9OJ.html"}
2022-03-07 16:57:37 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 16:57:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:57:39 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 16:57:39 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 206796
2022-03-07 16:57:39 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:57:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1S23EJ20514R9OJ.html> (referer: https://war.163.com/)
2022-03-07 16:57:39 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1S3I27A05504DOH.html"}
2022-03-07 16:58:57 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 16:58:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:58:59 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 16:58:59 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 212590
2022-03-07 16:58:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 16:58:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1S3I27A05504DOH.html> (referer: https://war.163.com/)
2022-03-07 16:58:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://war.163.com/photoview/4T8E0001/2313489.html"}
2022-03-07 17:01:48 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:01:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:01:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:01:50 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 113153
2022-03-07 17:01:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:01:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://war.163.com/photoview/4T8E0001/2313489.html> (referer: https://war.163.com/)
2022-03-07 17:01:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/war/article/H1P7AS7E000181KT.html"}
2022-03-07 17:06:02 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:06:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:06:04 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:06:04 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 298822
2022-03-07 17:06:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:06:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/war/article/H1P7AS7E000181KT.html> (referer: https://war.163.com/)
2022-03-07 17:06:04 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1P3379E0514EGPO.html"}
2022-03-07 17:09:01 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:09:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:09:03 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:09:03 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 194216
2022-03-07 17:09:03 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:09:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1P3379E0514EGPO.html> (referer: https://war.163.com/)
2022-03-07 17:09:03 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/war/article/H1P7E93V000181KT.html"}
2022-03-07 17:11:07 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:11:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:11:09 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:11:09 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 313575
2022-03-07 17:11:09 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:11:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/war/article/H1P7E93V000181KT.html> (referer: https://war.163.com/)
2022-03-07 17:11:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://war.163.com/photoview/4T8E0001/2313490.html"}
2022-03-07 17:14:11 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:14:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:14:13 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:14:13 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 135279
2022-03-07 17:14:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://war.163.com/photoview/4T8E0001/2313490.html> (referer: https://war.163.com/)
2022-03-07 17:14:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/war/article/H1RO6QDI000181KT.html"}
2022-03-07 17:19:13 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 500 1117
2022-03-07 17:19:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:19:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/war/article/H1P7KBE4000181KT.html"}
2022-03-07 17:19:34 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 500 1171
2022-03-07 17:19:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:19:34 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 17:19:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RV2G0L0514R9OJ.html> (failed 2 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1RV2G0L0514R9OJ.html took longer than 180.0 seconds..
2022-03-07 17:19:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RT08260514R9P4.html> (failed 2 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1RT08260514R9P4.html took longer than 180.0 seconds..
2022-03-07 17:19:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RQF5JH05504DOH.html> (failed 2 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1RQF5JH05504DOH.html took longer than 180.0 seconds..
2022-03-07 17:19:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RKREE305504DOH.html> (failed 2 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1RKREE305504DOH.html took longer than 180.0 seconds..
2022-03-07 17:19:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RM9CE705504DOH.html> (failed 2 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1RM9CE705504DOH.html took longer than 180.0 seconds..
2022-03-07 17:19:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1NHO1EL0514FGV8.html> (failed 2 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1NHO1EL0514FGV8.html took longer than 180.0 seconds..
2022-03-07 17:19:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1O4QBUB0514R9OJ.html> (failed 2 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1O4QBUB0514R9OJ.html took longer than 180.0 seconds..
2022-03-07 17:19:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.163.com/war/article/H1RO6QDI000181KT.html>
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
StopIteration: <200 https://www.163.com/war/article/H1RO6QDI000181KT.html>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_response
    response = yield deferred_from_coro(method(request=request, response=response, spider=spider))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\middlewares.py", line 70, in process_response
    bro.get(request.url)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 436, in get
    self.execute(Command.GET, {'url': url})
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 424, in execute
    self.error_handler.check_response(response)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 247, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: timeout: Timed out receiving message from renderer: 292.042
  (Session info: headless chrome=99.0.4844.51)
Stacktrace:
Backtrace:
	Ordinal0 [0x007369A3+2582947]
	Ordinal0 [0x006CA6D1+2139857]
	Ordinal0 [0x005C3A98+1063576]
	Ordinal0 [0x005B5727+1005351]
	Ordinal0 [0x005B4727+1001255]
	Ordinal0 [0x005B4AF7+1002231]
	Ordinal0 [0x005BEF9F+1044383]
	Ordinal0 [0x005C962B+1087019]
	Ordinal0 [0x005CBD40+1097024]
	Ordinal0 [0x005B4DF6+1002998]
	Ordinal0 [0x005C94D5+1086677]
	Ordinal0 [0x00618616+1410582]
	Ordinal0 [0x00608366+1344358]
	Ordinal0 [0x005E5176+1200502]
	Ordinal0 [0x005E6066+1204326]
	GetHandleVerifier [0x008DBE02+1675858]
	GetHandleVerifier [0x0099036C+2414524]
	GetHandleVerifier [0x007CBB01+560977]
	GetHandleVerifier [0x007CA8D3+556323]
	Ordinal0 [0x006D020E+2163214]
	Ordinal0 [0x006D5078+2183288]
	Ordinal0 [0x006D51C0+2183616]
	Ordinal0 [0x006DEE1C+2223644]
	BaseThreadInitThunk [0x76DBFA29+25]
	RtlGetAppContainerNamedObjectPath [0x77797A9E+286]
	RtlGetAppContainerNamedObjectPath [0x77797A6E+238]

2022-03-07 17:19:34 [scrapy.core.scraper] ERROR: Error processing {'author': '环球网资讯',
 'content': '\n'
            '                    '
            '【环球网快讯】据俄新社3月7日报道，俄罗斯外交部称，俄方对德国决定向乌克兰提供武器感到失望。\n'
            '                ',
 'followNum': '1503239',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 14:13:19\u3000来源: ',
 'readNum': '1327',
 'regTime': '',
 'retweetNum': '20',
 'source': '网易军事',
 'timestamp': '20220307171934',
 'title': '快讯！俄媒：俄外交部称对德国决定向乌克兰提供武器感到失望',
 'url': 'https://www.163.com/dy/article/H1S4HTIM0514R9OJ.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:19:34 [scrapy.core.scraper] ERROR: Error processing {'author': '环球网资讯',
 'content': '\n'
            '                    '
            '俄罗斯人道主义总部表示，俄罗斯武装部队将宣布从当地时间7日上午起进入“静默状态”。同时，在乌克兰基辅、马里乌波尔、哈尔科夫和苏梅等地开启人道主义通道。俄军方将使用无人机监控各地居民撤离情况，以防止乌方的破坏行动。（总台记者 '
            '王德禄）\n'
            '                ',
 'followNum': '1503239',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 13:30:28\u3000来源: ',
 'readNum': '12054',
 'regTime': '',
 'retweetNum': '82',
 'source': '网易军事',
 'timestamp': '20220307171934',
 'title': '俄武装部队将宣布从7日上午起进入“静默状态”',
 'url': 'https://www.163.com/dy/article/H1S23EJ20514R9OJ.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:19:34 [scrapy.core.scraper] ERROR: Error processing {'author': '环球时报军事',
 'content': '\n'
            '                    '
            '据今日俄罗斯电视台（RT）6日报道，俄罗斯国防部周六称，对乌克兰日托米尔市的一个军事设施进行的远程精确打击，摧毁了一个储存西方供应武器的仓库。伊戈尔·科纳申科夫 '
            '图源：外媒俄罗斯国防部发言人伊戈尔·科纳申科夫（Igor '
            'Konashenkov）表示，该仓库位于乌克兰西北部的一座军事基地。该基地用于存放美国、英国和瑞典提供的“标枪”和NLAW便携式反坦克系统，这些武器是在这次俄乌冲突开始之前运往乌克兰的。“标枪”导弹 '
            '图源：外媒科纳申科夫称，俄军在这次行动中摧毁的乌克兰军事基础设施目标现已超过2000个。这位发言人还宣布，对乌克兰东部城市马里乌波尔和伏尔诺华卡实施临时停火，停火时间为当地时间周六上午10点至下午4点。他说，俄罗斯和乌克兰军队已经同意建立人道主义走廊，让平民从这两个城市撤离。伊戈尔·科纳申科夫 '
            '图源：外媒普京2月24日下令在乌克兰东部地区采取特别军事行动，并指出俄罗斯没有占领乌克兰的计划，但将努力实现乌克兰的“非军事化和去纳粹化”。西方国家对此强烈谴责，并对俄罗斯实施一系列严厉制裁。（编辑：ZLQ）\n'
            '                ',
 'followNum': '231986',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 13:55:56\u3000来源: ',
 'readNum': '319',
 'regTime': '',
 'retweetNum': '16',
 'source': '网易军事',
 'timestamp': '20220307171934',
 'title': '白援助了？俄国防部：精确打击乌克兰一处武器库，西方军援被摧毁',
 'url': 'https://www.163.com/dy/article/H1S3I27A05504DOH.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:19:35 [scrapy.core.scraper] ERROR: Error processing {'author': None,
 'content': '',
 'followNum': None,
 'fromWhere': '',
 'pubTime': None,
 'readNum': None,
 'regTime': '',
 'retweetNum': None,
 'source': '网易军事',
 'timestamp': '20220307171935',
 'title': None,
 'url': None}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:19:35 [scrapy.core.scraper] ERROR: Error processing {'author': None,
 'content': '\n'
            '                    \n'
            '                    \n'
            '                        （原标题：卡拉其古边防连：借助野营拉练 开展多课目强训）\n'
            '                    \n'
            '                    \n'
            '                    官兵向目标区域挺进。姬文志 '
            '摄近日，新疆军区某边防团卡拉其古边防连在海拔4000多米的野外地域，进行多课目强化训练，在复杂生疏环境中，锤炼战斗技能。通过染毒地段。姬文志 '
            '摄“前方发现黄色烟雾！”行军途中，便突发情况，参训官兵临危不乱，快速穿戴防毒面具，通过染毒地段。现场演绎舞蹈。姬文志 '
            '摄文艺骨干发挥自身特长，为大家跳起了欢快的舞蹈，缓解行军疲劳。无人机侦察研判。姬文志 '
            '摄“‘敌方’实施热感应侦察！”新的“敌情”通报传来，指挥员快速研判，利用山地环境，组织人员成功躲避“敌机”侦察。“走一路、打一路、练一路，不仅提升了个人在严寒条件下作战能力，也暴露出自身存在的短板，下一步将在训练中逐项挂号销账。”新兵赵永龙说。组织战术行动。姬文志 '
            '摄近年来，卡拉其古边防连根据防区任务特点，常态化组织实兵实装演练，实战化水平不断提升。（姬文志、刘敬威、杜威摄影报道）\n'
            '                    \n'
            '                ',
 'followNum': None,
 'fromWhere': '',
 'pubTime': None,
 'readNum': '14',
 'regTime': '',
 'retweetNum': '2',
 'source': '网易军事',
 'timestamp': '20220307171935',
 'title': None,
 'url': 'https://3g.163.com/news/article/H1P7AS7E000181KT.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:19:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.163.com/war/article/H1P7KBE4000181KT.html>
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
StopIteration: <200 https://www.163.com/war/article/H1P7KBE4000181KT.html>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_response
    response = yield deferred_from_coro(method(request=request, response=response, spider=spider))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\middlewares.py", line 70, in process_response
    bro.get(request.url)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 436, in get
    self.execute(Command.GET, {'url': url})
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 424, in execute
    self.error_handler.check_response(response)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 247, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: net::ERR_NAME_NOT_RESOLVED
  (Session info: headless chrome=99.0.4844.51)
Stacktrace:
Backtrace:
	Ordinal0 [0x007369A3+2582947]
	Ordinal0 [0x006CA6D1+2139857]
	Ordinal0 [0x005C3A98+1063576]
	Ordinal0 [0x005C0551+1049937]
	Ordinal0 [0x005B5D9D+1007005]
	Ordinal0 [0x005B6A0E+1010190]
	Ordinal0 [0x005B5FFE+1007614]
	Ordinal0 [0x005B55F0+1005040]
	Ordinal0 [0x005B4727+1001255]
	Ordinal0 [0x005B49E6+1001958]
	Ordinal0 [0x005C518A+1069450]
	Ordinal0 [0x006188FD+1411325]
	Ordinal0 [0x0060854C+1344844]
	Ordinal0 [0x0061834A+1409866]
	Ordinal0 [0x00608366+1344358]
	Ordinal0 [0x005E5176+1200502]
	Ordinal0 [0x005E6066+1204326]
	GetHandleVerifier [0x008DBE02+1675858]
	GetHandleVerifier [0x0099036C+2414524]
	GetHandleVerifier [0x007CBB01+560977]
	GetHandleVerifier [0x007CA8D3+556323]
	Ordinal0 [0x006D020E+2163214]
	Ordinal0 [0x006D5078+2183288]
	Ordinal0 [0x006D51C0+2183616]
	Ordinal0 [0x006DEE1C+2223644]
	BaseThreadInitThunk [0x76DBFA29+25]
	RtlGetAppContainerNamedObjectPath [0x77797A9E+286]
	RtlGetAppContainerNamedObjectPath [0x77797A6E+238]

2022-03-07 17:19:35 [scrapy.core.scraper] ERROR: Error processing {'author': '看看新闻Knews',
 'content': '\n'
            '                    '
            '3月5日上午，根据财政部在全国人大会议上提交的政府预算草案报告，中国今年军费预算为1.45万亿元，同比增长7.1%，增幅比去年上调0.3百分点。外媒报道称，这是中国自2019年以来军费预算增幅首次突破7%，是近三年来最快增速。军事专家傅前哨表示，世界主要军事大国的国防支出在GDP中的占比一般都在2%～5%之间。如果比总量，也就是把几十年的军费开支都加起来，那么中国和其他军事大国相比就更少了。相比之下，2022年印度的军费开支提高到了652亿美元，美国2019-2020年度的军费预算高达7160亿美元，超过全球排名前十位的其他9个国家的总和。美国的军费是中国的将近4倍，美国人均军费高达中国人均军费的14.68倍。在此我们不禁要问某些外国媒体，对美国远远超出其防卫需要的巨额军费和极高的占比不吭一声，对某些西方国家计划把军费开支的占比提高到2%以上表示赞赏和欢迎，却对中国正常的军费开支说三道四。这种非理性的、罔顾事实的言论，不是双标是什么？(编辑：董亚欢 '
            '实习编辑：申秋）\n'
            '                ',
 'followNum': '1080485',
 'fromWhere': '',
 'pubTime': '\n                2022-03-06 09:50:06\u3000来源: ',
 'readNum': None,
 'regTime': '',
 'retweetNum': None,
 'source': '网易军事',
 'timestamp': '20220307171935',
 'title': '外媒炒作中国军费预算增速三年来最高 专家:这不是“双标”是什么',
 'url': 'https://www.163.com/dy/article/H1P3379E0514EGPO.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:19:35 [scrapy.core.scraper] ERROR: Error processing {'author': None,
 'content': '\n'
            '                    \n'
            '                    \n'
            '                        （原标题：战味十足！高清大图定格武警官兵火热练兵场景）\n'
            '                    \n'
            '                    \n'
            '                    '
            '连日来，武警新疆总队塔城支队着眼部队当前任务实际，灵活开展班组战术、刺杀、综合体能等课目训练，加紧练兵备战，进一步锤炼官兵技战术水平，提升打赢本领。尽管当前气温仍然较低，走进训练场，一片火热练兵景象，处处可见官兵们挑战自我、奋勇拼搏的身影。（肖生明 '
            '陈吕东 刘宗朋 伍志斌）\n'
            '                    \n'
            '                ',
 'followNum': None,
 'fromWhere': '',
 'pubTime': None,
 'readNum': '87',
 'regTime': '',
 'retweetNum': '9',
 'source': '网易军事',
 'timestamp': '20220307171935',
 'title': None,
 'url': 'https://3g.163.com/news/article/H1P7E93V000181KT.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:19:35 [scrapy.core.scraper] ERROR: Error processing {'author': None,
 'content': '',
 'followNum': None,
 'fromWhere': '',
 'pubTime': None,
 'readNum': None,
 'regTime': '',
 'retweetNum': None,
 'source': '网易军事',
 'timestamp': '20220307171935',
 'title': None,
 'url': None}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:19:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1NK0J9E0515CLPL.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:19:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1P2DO610550LMMF.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:19:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1QHMMD005504DOH.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:19:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1P1TVU10514D3UH.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:19:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1KM6M9U0515CCSC.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:19:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/news/article/H1OT9M0N0001899O.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:19:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1NSL0ID053469LG.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:19:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1O3K3DH05504DOH.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:20:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1N1KHO10514BQ68.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:20:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1MOA83705346936.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:20:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1R5U5SI0514R9OJ.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:20:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1MNR8F80514R9NP.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:20:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1MT39II05504DOH.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:20:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1MHGFPM05346936.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:20:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RDE6CJ0514R9OJ.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:20:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RKQ69O05504DOH.html> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2022-03-07 17:20:28 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 17:20:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1QSNHQR0514R9OJ.html"}
2022-03-07 17:23:05 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:23:05 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:23:07 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:23:07 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 208716
2022-03-07 17:23:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:23:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1QSNHQR0514R9OJ.html> (referer: https://war.163.com/)
2022-03-07 17:23:07 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 17:23:07 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1QKIBFK0514R9OJ.html"}
2022-03-07 17:23:42 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:23:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:23:44 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:23:44 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 204250
2022-03-07 17:23:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1QKIBFK0514R9OJ.html> (referer: https://war.163.com/)
2022-03-07 17:23:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1RKN0BU0514R9OJ.html"}
2022-03-07 17:24:20 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:24:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:24:22 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:24:22 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 225809
2022-03-07 17:24:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:24:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1RKN0BU0514R9OJ.html> (referer: https://war.163.com/)
2022-03-07 17:24:22 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1MIAREA0514R9OJ.html"}
2022-03-07 17:24:45 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:24:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:24:47 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:24:47 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 178758
2022-03-07 17:24:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:24:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1MIAREA0514R9OJ.html> (referer: https://war.163.com/)
2022-03-07 17:24:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1S7KJFM0514R9OJ.html"}
2022-03-07 17:24:56 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:24:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:24:58 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:24:58 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 114245
2022-03-07 17:24:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:24:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1S7KJFM0514R9OJ.html> (referer: https://war.163.com/)
2022-03-07 17:24:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/war/article/H1RNH9OH000181KT.html"}
2022-03-07 17:25:33 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:25:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:25:35 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:25:35 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 239760
2022-03-07 17:25:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:25:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/war/article/H1RNH9OH000181KT.html> (referer: https://war.163.com/)
2022-03-07 17:25:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1SA5GSN0514R9P4.html"}
2022-03-07 17:26:01 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:26:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:26:03 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:26:03 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 194992
2022-03-07 17:26:03 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:26:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1SA5GSN0514R9P4.html> (referer: https://war.163.com/)
2022-03-07 17:26:04 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1S7KJPF0514R9OJ.html"}
2022-03-07 17:26:15 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:26:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:26:17 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:26:17 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 201457
2022-03-07 17:26:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:26:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1S7KJPF0514R9OJ.html> (referer: https://war.163.com/)
2022-03-07 17:26:17 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 17:26:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.163.com/dy/article/H1RTQ4DF0514R9OJ.html> (failed 2 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1RTQ4DF0514R9OJ.html took longer than 180.0 seconds..
2022-03-07 17:26:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.163.com/dy/article/H1MOA83705346936.html> (failed 3 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1MOA83705346936.html took longer than 180.0 seconds..
2022-03-07 17:26:17 [scrapy.core.scraper] ERROR: Error processing {'author': '环球网资讯',
 'content': '\n'
            '                    '
            '当地时间6日，俄乌谈判乌方代表团成员、乌克兰人民公仆党议会党团主席阿拉哈米亚表示，未来5到10年间，北约并不准备讨论乌克兰加入该组织这一问题。他表示，乌方不会再致力于提交加入北约的申请，而是将讨论某种“非北约模式”。在这一问题上，乌方必须与之开展对话的并不仅仅是俄罗斯这一个国家。（总台记者 '
            '王德禄）\n'
            '                ',
 'followNum': '1503289',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 02:37:21\u3000来源: ',
 'readNum': '3640',
 'regTime': '',
 'retweetNum': '254',
 'source': '网易军事',
 'timestamp': '20220307172617',
 'title': '俄乌谈判乌方代表团成员：乌方不再致力于申请加入北约',
 'url': 'https://www.163.com/dy/article/H1QSNHQR0514R9OJ.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:26:17 [scrapy.core.scraper] ERROR: Error processing {'author': '环球网资讯',
 'content': '\n'
            '                    '
            '当地时间6日，俄乌谈判乌方代表团成员、乌克兰人民公仆党议会党团主席阿拉哈米亚表示，双方均满意能够互相听取对方的立场，并开展积极讨论。他表示，目前唯一无法同俄方达成一致的是克里米亚问题以及承认卢甘斯克和顿涅茨克独立。（总台记者 '
            '王德禄）\n'
            '                ',
 'followNum': '1503306',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 00:14:42\u3000来源: ',
 'readNum': '55',
 'regTime': '',
 'retweetNum': '6',
 'source': '网易军事',
 'timestamp': '20220307172617',
 'title': '俄乌谈判乌方代表团成员：双方满意目前谈判进程',
 'url': 'https://www.163.com/dy/article/H1QKIBFK0514R9OJ.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:26:17 [scrapy.core.scraper] ERROR: Error processing {'author': '环球网资讯',
 'content': '\n'
            '                    '
            '当地时间3月6日，美国国务卿布林肯表示，北约成员国已获准向乌克兰提供战机。当被问及作为北约成员国的波兰政府是否可以向乌克兰提供战机时，布林肯说：“这得到了批准……事实上，我们正在与我们的波兰朋友讨论，如果他们真的选择向乌克兰提供这些战机，我们可以做些什么来满足他们的需求。”（央视记者 '
            '顾乡）\n'
            '                ',
 'followNum': '1503306',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 09:36:29\u3000来源: ',
 'readNum': '1079',
 'regTime': '',
 'retweetNum': '46',
 'source': '网易军事',
 'timestamp': '20220307172617',
 'title': '美国务卿：北约国家已获准向乌克兰提供战机',
 'url': 'https://www.163.com/dy/article/H1RKN0BU0514R9OJ.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:26:17 [scrapy.core.scraper] ERROR: Error processing {'author': '环球网资讯',
 'content': '\n'
            '                    新华社首尔3月5日电（记者陆睿 '
            '杜白羽）韩国联合参谋本部5日说，朝鲜当天向东部海域方向发射一枚疑似弹道导弹的发射体。韩国联合参谋本部当天上午在向媒体发送的短信中公开了这一消息。它还说，这枚发射体是从朝鲜顺安一带发射的。目前韩国军方正在监视朝鲜是否有追加发射的相关动向，并做好应对态势。自1月5日至本次试射前，朝鲜进行了7次导弹试射和一次侦察卫星发射试验。据朝中社2月28日报道，朝鲜于27日进行了一次侦察卫星的发射试验，其目的是检验其高分辨率摄影系统、数据传输系统和运行精确度等。\n'
            '                ',
 'followNum': '1503306',
 'fromWhere': '',
 'pubTime': '\n                2022-03-05 10:18:41\u3000来源: ',
 'readNum': '29',
 'regTime': '',
 'retweetNum': '3',
 'source': '网易军事',
 'timestamp': '20220307172617',
 'title': '韩国军方说朝鲜向东部海域发射疑似弹道导弹发射体',
 'url': 'https://www.163.com/dy/article/H1MIAREA0514R9OJ.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:26:18 [scrapy.core.scraper] ERROR: Error processing {'author': '环球网资讯',
 'content': '\n'
            '                    '
            '当地时间7日中午，印度总理莫迪与乌克兰总统泽连斯基通电话。电话持续了35分钟，双方主要探讨了当下乌克兰的局势。（总台记者 '
            '王建兵）\n'
            '                ',
 'followNum': '1503306',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 15:07:13\u3000来源: ',
 'readNum': None,
 'regTime': '',
 'retweetNum': None,
 'source': '网易军事',
 'timestamp': '20220307172618',
 'title': '印度总理莫迪与乌克兰总统泽连斯基通电话',
 'url': 'https://www.163.com/dy/article/H1S7KJFM0514R9OJ.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:26:18 [scrapy.core.scraper] ERROR: Error processing {'author': None,
 'content': '\n'
            '                    \n'
            '                    \n'
            '                        （原标题：俄乌冲突第11天：俄方称摧毁2203处乌克兰军事基础设施）\n'
            '                    \n'
            '                    \n'
            '                    '
            '俄方：摧毁2203处乌克兰军事基础设施3月6日，俄国防部新闻发言人伊戈尔·科纳申科夫少将发布简报，自2月24日开展特别军事心动以来，俄武装部队已对2203处乌克兰军事目标进行打击，其中76个指挥所和通信中心、111套防空武器系统（S-300、“山毛榉”M1和“黄蜂”）以及71个雷达站；分别在地面摧毁和空中击落69架和24架飞机或直升机、击毁778辆坦克和其他装甲车辆、77门多管火箭炮、279门各式迫击炮与火炮、553辆军用车辆和62架无人机。被伏击毁坏的乌军卡车 '
            '图源：社交媒体俄国防部：已基本解除乌克兰空军战斗力当地时间3月6日，俄罗斯国防部举行新闻发布会，通报了俄罗斯对乌克兰军事行动的最新进展。通报称，俄军已基本解除了乌克兰武装力量空军的战斗力，并警告地区邻国不要为乌克兰战机提供机场作为基地。俄国防部还表示，俄方在军事行动中发现了由美国资助的、在乌克兰境内实施的军事生物计划。临近俄罗斯边境的几个乌克兰生物实验室曾从事生化武器研发。俄罗斯对乌克兰军事行动开始后，这些实验室紧急销毁了能够引发鼠疫、炭疽和霍乱的病毒。目前，俄方已经公布了相关材料。美国称正与欧洲盟友商谈禁止进口俄罗斯石油美国国务卿布林肯3月6日表示，美国正在与欧洲盟友合作，共同研究禁止进口俄罗斯石油的可能性，以进一步惩罚“俄罗斯入侵乌克兰”的行为。布林肯表示，已与美国总统拜登和内阁其他成员就禁止进口俄罗斯石油的问题进行了通话。美国常驻联合国代表格林菲尔德3月6日表示，美国还可以在另外两个领域采取额外措施对俄罗斯施压，包括宣布战争罪和帮助向乌克兰运送战斗机。俄乌谈判乌方代表团成员：乌方不再致力于申请加入北约当地时间6日，俄乌谈判乌方代表团成员、乌克兰人民公仆党议会党团主席阿拉哈米亚表示，未来5到10年间，北约并不准备讨论乌克兰加入该组织这一问题。他表示，乌方不会再致力于提交加入北约的申请，而是将讨论某种“非北约模式”。在这一问题上，乌方必须与之开展对话的并不仅仅是俄罗斯这一个国家。马克龙与普京第4次通话，俄方确认将轰炸敖德萨当地时间6日，俄罗斯总统普京与法国总统马克龙进行通话。这是自俄乌冲突以来，双方第4次通电话。针对马克龙对乌克兰境内核电站安全的关注，普京表示，扎波罗热核电站事件是乌克兰极端分子无耻炒作的一部分，企图将可能发生的严重事故的责任转嫁到俄军身上。目前该核电站处于俄军的有效保护中。同时，俄军还保卫切尔诺贝利核电站。在回应法方有关就保障乌克兰境内核设施安全举行国际原子能机构、俄罗斯、乌克兰三方会晤的建议时，普京表示，这一建议在原则上是有益的，但需考虑会晤的形式，是以视频方式举行还是在第三国举行。另外，双方还讨论了从冲突区撤离平民的问题。普京指出，尽管3月5日俄方宣布进入“静默状态”，以从乌克兰马里乌波尔和沃尔诺瓦哈撤离居民和外国公民，但乌民族主义分子破坏了撤离计划。普京建议马克龙敦促乌克兰当局遵守国际人道主义法准则。普京还向马克龙通报了俄乌谈判情况。普京表示，俄方将在乌方无条件完成俄方要求的前提下继续对话。法国总统府表示，俄罗斯方面确认将轰炸敖德萨港。\n'
            '                    \n'
            '                ',
 'followNum': None,
 'fromWhere': '',
 'pubTime': None,
 'readNum': '49',
 'regTime': '',
 'retweetNum': '5',
 'source': '网易军事',
 'timestamp': '20220307172618',
 'title': None,
 'url': 'https://3g.163.com/war/article/H1RNH9OH000181KT.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:26:18 [scrapy.core.scraper] ERROR: Error processing {'author': '澎湃新闻',
 'content': '\n'
            '                    '
            '3月7日，国务委员兼外交部长王毅就“中国的外交政策和对外关系”回答中外记者提问。有记者提问，请问西方对俄罗斯和中国日益增长的集体制裁压力将如何影响俄中关系的进一步发展？王毅表示，中国和俄罗斯我们都是联合国安理会常任理事国，是彼此最重要的紧密邻邦和战略伙伴。中俄关系作为世界上最关键的双边关系之一，我们的合作不仅给两国人民带来利益和福祉，也有利于世界的和平、稳定与发展。去年，我们双方共同纪念《中俄睦邻友好合作条约》签署20周年。在日趋复杂的国际战略环境下，这一条约所承载的世代友好、合作共赢理念，不仅对中俄双方，而且对世界各国都具有十分积极和现实的借鉴意义。王毅强调指出，中俄关系具有独立自主价值，建立在不结盟、不对抗、不针对第三方基础之上，更不受第三方的干扰和挑拨。这既是对历史经验的总结，也是对国际关系的创新。不久前，两国共同发表《关于新时代国际关系和全球可持续发展的联合声明》，清晰无误地向世界表明，我们共同反对重拾冷战思维，反对挑动意识形态对抗，主张推进国际关系民主化，主张维护《联合国宪章》宗旨和原则。中俄关系发展有着清晰的历史逻辑，具有强大的内生动力，两国人民的友谊坚如磐石，双方的合作前景十分广阔。不管国际风云如何险恶，中俄双方都将保持战略定力，将新时代全面战略协作伙伴关系不断推向前进。\n'
            '                ',
 'followNum': '4057172',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 15:51:25\u3000来源: ',
 'readNum': None,
 'regTime': '',
 'retweetNum': None,
 'source': '网易军事',
 'timestamp': '20220307172618',
 'title': '王毅：中俄关系具有独立自主价值，不受第三方的干扰和挑拨',
 'url': 'https://www.163.com/dy/article/H1SA5GSN0514R9P4.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:26:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.163.com/dy/article/H1MOA83705346936.html>
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 355, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.163.com/dy/article/H1MOA83705346936.html took longer than 180.0 seconds..
2022-03-07 17:26:18 [scrapy.core.scraper] ERROR: Error processing {'author': '环球网资讯',
 'content': '\n'
            '                    '
            '当地时间3月6日，正在摩尔多瓦访问的美国国务卿布林肯表示，如果波兰政府向乌克兰提供米格-29战斗机，美国会积极考虑用美制F-16战机替代米格战机的可能性，但目前关于此事尚无具体时间表。6日晚些时候，波兰政府发言人穆勒在总理府的发布会上就布林肯的上述表态进行了澄清。穆勒称，目前波兰并未决定向乌克兰派遣战机，“北约行动的尺度仍在讨论中，关于该话题（向乌提供战机）尚未作出任何结论”。此外，穆勒还明确否认了有战斗机从波兰境内的机场起飞前往乌克兰执行战斗任务的报道，称其为“假消息”。（总台记者 '
            '徐明）\n'
            '                ',
 'followNum': '1503306',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 15:07:13\u3000来源: ',
 'readNum': '10',
 'regTime': '',
 'retweetNum': '1',
 'source': '网易军事',
 'timestamp': '20220307172618',
 'title': '波兰政府发言人：目前并未决定向乌克兰派遣战机',
 'url': 'https://www.163.com/dy/article/H1S7KJPF0514R9OJ.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:26:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1N1KHO10514BQ68.html"}
2022-03-07 17:26:31 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:26:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:26:33 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:26:33 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 199241
2022-03-07 17:26:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:26:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1N1KHO10514BQ68.html> (referer: https://war.163.com/)
2022-03-07 17:26:33 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 17:26:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1RDE6CJ0514R9OJ.html"}
2022-03-07 17:28:16 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:28:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:28:18 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:28:18 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 160092
2022-03-07 17:28:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:28:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1RDE6CJ0514R9OJ.html> (referer: https://war.163.com/)
2022-03-07 17:28:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.163.com/dy/article/H1R5U5SI0514R9OJ.html> (failed 3 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1R5U5SI0514R9OJ.html took longer than 180.0 seconds..
2022-03-07 17:28:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.163.com/dy/article/H1MNR8F80514R9NP.html> (failed 3 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1MNR8F80514R9NP.html took longer than 180.0 seconds..
2022-03-07 17:28:18 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 17:28:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.163.com/dy/article/H1MT39II05504DOH.html> (failed 3 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1MT39II05504DOH.html took longer than 180.0 seconds..
2022-03-07 17:28:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.163.com/dy/article/H1MHGFPM05346936.html> (failed 3 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1MHGFPM05346936.html took longer than 180.0 seconds..
2022-03-07 17:28:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.163.com/dy/article/H1O3K3DH05504DOH.html> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2022-03-07 17:28:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.163.com/dy/article/H1RKQ69O05504DOH.html> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2022-03-07 17:28:18 [scrapy.core.scraper] ERROR: Error processing {'author': '参考消息',
 'content': '\n'
            '                    参考消息网3月5日报道 '
            '据美国《时代》周刊网站3月3日报道，两名美国国防部官员说，在乌克兰战争引发的紧张局势加剧之际，美国军方与俄罗斯军方建立了沟通热线，以防止这两个核大国之间发生意外冲突。这条所谓的冲突化解热线旨在确保两国飞行员或战舰在东欧执行日常任务时不会相互误射。报道称，这条军方沟通渠道的一端是位于德国斯图加特的美军欧洲司令部，它是在俄罗斯对五角大楼的要求做出回应后于3月1日设立的。官员们说，保持沟通以避免军队之间的意外对抗至关重要，这样敌对状态就不会失控。报道指出，这不是两国第一次建立这样的机制。俄罗斯2015年介入叙利亚内战后，美俄军方建立了一条秘密渠道。俄罗斯介入叙利亚是为支持其盟友叙利亚总统巴沙尔·阿萨德；而美国出动飞机轰炸“伊斯兰国”组织的据点，并部署特种部队执行地面的定向任务。当时，这条冲突化解渠道包括一条不安全的电话线和一个谷歌邮箱账户，事实证明它对于避免灾难性事故是有用的。东欧的情况有所不同。美国及其盟友的行动范围与俄罗斯不同，但拜登政府认识到了误判的可能性。美国官员说，东欧的这一渠道将包括一条电话线，但他们拒绝透露更多细节。\n'
            '                ',
 'followNum': '527163',
 'fromWhere': '',
 'pubTime': '\n                2022-03-05 14:46:08\u3000来源: ',
 'readNum': '1',
 'regTime': '',
 'retweetNum': '1',
 'source': '网易军事',
 'timestamp': '20220307172818',
 'title': '美媒：美俄军方开通热线防止擦枪走火',
 'url': 'https://www.163.com/dy/article/H1N1KHO10514BQ68.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:28:18 [scrapy.core.scraper] ERROR: Error processing {'author': '环球网资讯',
 'content': '\n'
            '                    '
            '【环球时报综合报道】曾经妄言“台海若开战，澳大利亚不参加难以想象”的澳大利亚国防部长达顿，这两天似乎“后退”了。英国《卫报》6日称，他当天在接受澳大利亚广播公司（ABC）采访时再被问及台海问题时称，“到时候我们会根据国家的最大利益做出决定”。评论称，达顿新的表态不如之前强硬。但他在采访中依然表示，一旦台海开战，澳会向台湾提供军火，武装民进党当局。2021年11月，达顿在接受采访时被问到台海战事的前景时称，“如果美国选择采取行动，我们不参加美国的行动，这将是不可想象的”。《卫报》称，这一言论引发轩然大波，被指偏离了澳大利亚两党长期以来坚守的政策，特别是考虑到美国对于是否武力保卫台湾也一直保持“战略模糊”。澳政界众多人士指责达顿将澳大利亚拉入大国的战争。报道称，达顿在最新的采访中没有重复这一言论，关于台湾的措辞“显得更加谨慎”。ABC称，被问到澳是否会提供武器给台湾时，达顿称，澳大利亚将“尽一切能力吓阻中国”，并称“软弱的立场是无法争取和平的”。达顿还将台湾局势和乌克兰相提并论，称中国应该从俄罗斯身上“吸取教训”，不要用武力改变台海现状，因为这会出现中国“想象不到的复杂结果”。ABC称，对于达顿就台海战争的假设性问题发表看法，在野党工党国防事务发言人奥康纳提出批评，认为达顿身为国防部长，绝不应该针对澳大利亚与一个核武大国全面交战的假设性问题作出正面回答。“我不记得在我们的历史上，尤其是最近的历史上，任何一位国防部长会正面回答一个关于我们是否会与核超级大国展开全面战争的假设性问题。”（高雷）延伸阅读澳防长再发表反华言论：对抗中国，否则将失去下一个十年作为美国的忠实“兄弟”，澳大利亚一直充当着“反华”急先锋，并且与许多国家的“口头反华”不同，澳大利亚“反华”非常认真。近日，澳大利亚国防部长又开始口出狂言。据悉，澳大利亚国防部长达顿7日声称，美国及其盟国在过去十年“默许”中国在南海“扩张”， '
            '除非对抗中国，否则美澳及其盟国将“失去下一个十年”。另外，达顿还搬出了在2021年成立的美英澳三边安全伙伴关系“奥库斯”， '
            '澳大利亚将在2038年之前拥有自己的核潜艇。其实，达顿作为澳大利亚的国防部长此前便多次出言不逊，在其担任内政部长期间，他就发表过多次“反华”言论。更过分的是，达顿甚至还对台湾问题发表过不当言论。对于达顿的种种“表现”，不少网友都持批评态度，认为他只是在为自己的升职做样子。尽管达顿曾经是警察出身，但达顿可以说是一个死硬“反华”分子、极端右翼分子。许多澳媒称此人是“从来没有一位澳大利亚部长像他一样对中国采取如此有攻击性的言行”。当然，诸如达顿这种横在中澳关系之中的“老鼠屎”还不少。这些右翼分子一直跟随美国步伐在涉华问题上反复横跳，导致中澳关系面临重大困难。不过，随着新一年的到来，新一任中国驻澳大使将前往澳履职，有可能中澳官方的对话大门会被打开。当然，中澳对话对澳大利亚来说更加的重要，澳大利亚现在经济高度依赖中国，澳大利亚60%的铁矿、55%的煤炭都要出口给中国。就2020年而言，中澳贸易额便超过一万亿人民币，中国始终是澳大利亚重要贸易合作伙伴。2021年，中国国内生产总值（GDP）达到114.4万亿元，再一次突破一百万亿元大关。与2022年同期相比，中国GDP增长8.1%。从数据可以看出，中国始终是全球经济复苏的引擎，这是美国无法否认的。另外，中国拥有相当庞大的消费市场，澳大利亚如果真的要一条道儿走到黑，这势必会给澳方带来了不小损失。值得注意的是，今年是澳大利亚的大选之年，可以预见，今年的选举将会非常激烈，也扑朔迷离。而选举结果势必将影响到大家都关心的中澳关系。当然，这或许会成为中澳关系改善的契机。局势有变？澳大选争斗牵扯中国，立陶宛最大反对党为与华对话要授权受美国驱使的澳大利亚、立陶宛在遭遇各种碰壁后，似乎在内部产生了巨大分歧，毕竟谁也不愿意无底线地“心甘情愿”付出。莫里森因大选而恼怒攀咬澳大利亚5月大选临近，但莫里森政府及其所在党派的民众支持率却大幅下跌，被澳大利亚工党所超越。其实这也在预料之中，毕竟在莫里森政府的执政下，抗疫不力、经济不增反陷入困境，这些确凿的事实都让民众十分不满。眼见执政生涯即将走向终结的莫里森这时喊出了“中国操控选举”试图甩锅中国，以“中国威胁论”来转移民众的注意力，不仅老调重弹提到了对华贸易之惨，还声称工党领袖安东尼·阿尔巴尼斯占优是中国政府“挑选好了马”，工党副领袖理查德·马斯勒是“中国选定的人”，把美国“洗衣粉”学了个十成十，炮制了“中国操纵”和达顿一唱一和把工党安排得明明白白，以“中国干涉澳大利亚大选”企图造势呼应“中国威胁”。莫里森与达顿莫里森之所以如此，一是为了打击对手，二是此前维多利亚州和西澳大利亚州为参加中国进博会而与联邦政府“分道扬镳”，这都让他躁动不安。但由于莫里森操弄中国议题次数过多，每每在政府陷入困境时就搬出这一套来转移民众视线，但在美国都开始谋求与中国关系正常化的环境下，澳大利亚的民众听多了莫里森相关言论后，一点儿也不“感冒”，只想得到更实在的东西和好处——拿点政绩出来啊，别老拿中国说事。由于多次挑衅中国，造成了对澳大利亚对华贸易、对亚太地区整体贸易的伤害，自己有限的政治外交能力使得情况更加恶化，只能把所谓的“国家安全”当作参加选举“核心竞争力”的莫里森，反倒自曝其短显露了他的黔驴技穷、乏善可陈。莫里森将自己的对内对外失败归咎于中方，但可悲的是，澳大利亚安全情报组织（ASIO）的负责人伯吉斯都看不下去了，“不相信外国政府可以真的改变澳选举结果”。阿尔巴尼斯随着选举的倒计时，为了一争高下的执政在野两党必不会少各种互相攻讦，美国自不愿意失去一个挡枪炮灰，所以之后牵扯中国的情况还将时不时出现。立陶宛反对党主席想和中国修复关系在某种方面来说，之所以牵扯中国，也是从另一方面证明了如今的中国在世界上的重要和影响力。类似澳大利亚政坛的状况还发生在立陶宛。这两位同命相怜抱团取暖的“难兄难弟”都面临了内部分歧产生了需要改善与中国关系的局面，这时候立陶宛最大反对党“绿党和农民联盟”主席雷蒙纳斯·卡尔保斯基斯，向立总理希莫尼特索要自己与中国谈判的授权，以使立陶宛与中国的关系正常化。立陶宛历经数次转变，从紧随美国对华挑衅、满嘴狡辩绝不认错、缓兵之计找欧盟求助、到如今的内部分歧。卡尔保斯基斯非常直接地给了立陶宛总理希莫尼特和外交部长兰茨贝尔吉斯的公开信——“如果你们中没有人能够或愿意改善对华关系，那么我请你们给我正式授权，以寻求与中国达成协议并纠正你们的错误。”卡尔保斯基斯卡尔保斯基斯喊话中国，希望中国政府最大限度地避免做出损害立陶宛民众和企业的决定，并等待摒弃现有操作的下一届政府。他的意思是，错在立陶宛现政府，而不是立陶宛人民和企业。但卡尔保斯基斯看似“公正”的表态背后，仍然充满了西方傲慢，他所提议的条件是——更改“台湾代表处”的名称。卡尔保斯基斯居然认为，立陶宛可以对台湾进行各种“和平”方式表达援助和支持，但不能是通过失去数十亿商业利益的方式。于是他怒斥现政府不肯认错的态度对立陶宛带来的伤害，当然同时他自己也怀疑能否得到授权，毕竟如果愿意授权的话，也不至于走到这一步。但卡尔保斯基斯知其然不知其所以然，之所以中国如此看重这个称谓，背后是对国家完整的决心。实际上，不管是澳大利亚的政坛闹剧，还是立陶宛方面的喊话，中方表示了遗憾，中国没兴趣干涉他国，中国只想发展搞合作，希望这些政客们能多从国家和人民的根本利益出发，不要只出于政治私利，不要听从某些势力而看不清楚发展态势，这对谁来说都是没有好处的。（易之）\n'
            '                ',
 'followNum': '1503306',
 'fromWhere': '',
 'pubTime': '\n                2022-03-07 07:29:20\u3000来源: ',
 'readNum': '2095',
 'regTime': '',
 'retweetNum': '20',
 'source': '网易军事',
 'timestamp': '20220307172818',
 'title': '改口“出兵台海”？澳防长又妄言：会向台湾提供军火，武装民进党当局',
 'url': 'https://www.163.com/dy/article/H1RDE6CJ0514R9OJ.html'}
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\utils\defer.py", line 150, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "D:\Python\Crawler_hyx\Crawl_hyx\Crawl_hyx\pipelines.py", line 142, in process_item
    "content": item["content"], "attributes": item['attributes'], "readNum": item["readNum"], "retweetNum": item["retweetNum"], "url": item["url"]}
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\item.py", line 94, in __getitem__
    return self._values[key]
KeyError: 'attributes'
2022-03-07 17:28:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.163.com/dy/article/H1R5U5SI0514R9OJ.html>
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 355, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.163.com/dy/article/H1R5U5SI0514R9OJ.html took longer than 180.0 seconds..
2022-03-07 17:28:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.163.com/dy/article/H1MNR8F80514R9NP.html>
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 355, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.163.com/dy/article/H1MNR8F80514R9NP.html took longer than 180.0 seconds..
2022-03-07 17:28:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.163.com/dy/article/H1MT39II05504DOH.html>
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 355, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.163.com/dy/article/H1MT39II05504DOH.html took longer than 180.0 seconds..
2022-03-07 17:28:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.163.com/dy/article/H1MHGFPM05346936.html>
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 355, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.163.com/dy/article/H1MHGFPM05346936.html took longer than 180.0 seconds..
2022-03-07 17:28:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.163.com/dy/article/H1O3K3DH05504DOH.html>
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2022-03-07 17:28:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://www.163.com/dy/article/H1RKQ69O05504DOH.html>
Traceback (most recent call last):
  File "D:\Python\Crawler_hyx\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 44, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2022-03-07 17:28:28 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 17:29:03 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1NK0J9E0515CLPL.html"}
2022-03-07 17:30:54 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:30:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:30:56 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:30:56 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 201527
2022-03-07 17:30:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:30:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1NK0J9E0515CLPL.html> (referer: https://war.163.com/)
2022-03-07 17:30:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.163.com/dy/article/H1NSL0ID053469LG.html> (failed 3 times): User timeout caused connection failure: Getting https://www.163.com/dy/article/H1NSL0ID053469LG.html took longer than 180.0 seconds..
2022-03-07 17:30:56 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2022-03-07 17:30:56 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.163.com/news/article/H1OT9M0N0001899O.html> (failed 3 times): User timeout caused connection failure: Getting https://www.163.com/news/article/H1OT9M0N0001899O.html took longer than 180.0 seconds..
2022-03-07 17:30:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1QHMMD005504DOH.html"}
2022-03-07 17:34:08 [urllib3.connectionpool] DEBUG: http://localhost:56522 "POST /session/068407d0b0b91b75afed2bdec16c762e/url HTTP/1.1" 200 14
2022-03-07 17:34:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:34:10 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/source {}
2022-03-07 17:34:10 [urllib3.connectionpool] DEBUG: http://localhost:56522 "GET /session/068407d0b0b91b75afed2bdec16c762e/source HTTP/1.1" 200 214906
2022-03-07 17:34:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2022-03-07 17:34:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.163.com/dy/article/H1QHMMD005504DOH.html> (referer: https://war.163.com/)
2022-03-07 17:34:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1P2DO610550LMMF.html"}
2022-03-07 17:36:49 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2022-03-07 17:36:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1P1TVU10514D3UH.html"}
2022-03-07 17:36:49 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (2): localhost:56522
2022-03-07 17:36:53 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/068407d0b0b91b75afed2bdec16c762e/url'): Retry(total=2, connect=None, read=None, redirect=None, status=None)
2022-03-07 17:36:53 [urllib3.connectionpool] WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000025C4C5A1180>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。')': /session/068407d0b0b91b75afed2bdec16c762e/url
2022-03-07 17:36:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (3): localhost:56522
2022-03-07 17:36:57 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/068407d0b0b91b75afed2bdec16c762e/url'): Retry(total=1, connect=None, read=None, redirect=None, status=None)
2022-03-07 17:36:57 [urllib3.connectionpool] WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000025C4C5A2620>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。')': /session/068407d0b0b91b75afed2bdec16c762e/url
2022-03-07 17:36:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (4): localhost:56522
2022-03-07 17:37:01 [urllib3.util.retry] DEBUG: Incremented Retry for (url='/session/068407d0b0b91b75afed2bdec16c762e/url'): Retry(total=0, connect=None, read=None, redirect=None, status=None)
2022-03-07 17:37:01 [urllib3.connectionpool] WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000025C4C5A3250>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。')': /session/068407d0b0b91b75afed2bdec16c762e/url
2022-03-07 17:37:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (5): localhost:56522
2022-03-07 17:37:05 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://localhost:56522/session/068407d0b0b91b75afed2bdec16c762e/url {"url": "https://www.163.com/dy/article/H1RTQ4DF0514R9OJ.html"}
2022-03-07 17:37:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (6): localhost:56522
